syntax = "proto3";

package tensorflow.muprover;

import "tensorflow/core/framework/tensor.proto";

service ReplayBuffer {
  rpc NumGames(Empty) returns (NumGamesResponse) {}
  rpc SaveHistory(GameHistory) returns (NumGamesResponse) {}
  rpc SaveMultipleHistory(stream GameHistory) returns (NumGamesResponse) {}
  rpc SampleBatch(MiniBatchRequest) returns (stream MiniBatchResponse) {}
  rpc Stats(StatsRequest) returns (StatsResponse) {}
  rpc BackupBuffer(Empty) returns (stream GameHistory) {}
}

message Empty {}

message NumGamesResponse {
  int32 num_games = 1;
}

message StatsRequest {
  bool detailed = 1;
}

message StatsResponse {
  map<string, float> metrics = 1;
}

message GameHistory {
  repeated TensorProto observations = 1;
  repeated int32 to_plays = 2;
  repeated int32 actions = 3;
  repeated float rewards = 4;
  repeated float root_values = 5;
  repeated TensorProto policies = 6;
  map<string, bytes> metadata = 7;
}

message GameHistoryList {
  repeated GameHistory histories = 1;
}

message MiniBatchRequest {
  int32 batch_size = 1;
}

message MiniBatchResponse {
  TensorProto batch_observations = 1;
  TensorProto batch_actions = 2;
  TensorProto batch_target_rewards = 3;
  TensorProto batch_target_values = 4;
  TensorProto batch_target_policies = 5;
}
